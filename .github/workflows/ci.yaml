# name: CI Pipeline

# on:
#   push:   # Trigger pipeline on every push event to the repository

# jobs:
#   project-testing:
#     runs-on: ubuntu-latest   # Use latest GitHub-hosted Ubuntu runner

#     env:  # GLOBAL ENVIRONMENT VARIABLES for all steps
#       PYTHONPATH: ${{ github.workspace }}   # Allows Python to resolve modules inside 'src' folder
#       AWS_REGION: ap-south-1

#     steps:
#       # STEP 1: Checkout code from GitHub
#       - name: Checkout code
#         uses: actions/checkout@v4

#       # STEP 2: Set up Python environment
#       - name: Set up Python
#         uses: actions/setup-python@v4
#         with:
#           python-version: '3.10'

#       # STEP 3: Cache pip dependencies for faster pipeline runs
#       - name: Cache pip dependencies
#         uses: actions/cache@v3
#         with:
#           path: ~/.cache/pip
#           key: ${{ runner.os }}-pip-${{ hashFiles('requirements_dev.txt') }}
#           restore-keys: |
#             ${{ runner.os }}-pip-

#       # STEP 4: Install required Python packages
#       - name: Install Python dependencies (quiet & faster)
#         run: |
#           python -m pip install --upgrade pip --quiet
#           pip install -r requirements_dev.txt --quiet

#       # STEP 5: Install DVC and Dagshub for data versioning and remote storage
#       - name: Setup DVC and Dagshub
#         run: |
#           pip install --quiet dvc[s3] dagshub

#       # STEP 6: Pull dataset and artifacts tracked by DVC from S3
#       - name: Pull DVC data from S3
#         env:
#           AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
#           AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
#           DAGSHUB_PAT: ${{ secrets.DAGSHUB_PAT }}
#         run: |
#           dvc pull --quiet
#           test -f artifacts/data/vectorized/test_vectorized.csv   # Validate if key file is pulled

#       # STEP 7: Re-run the entire data pipeline using DVC
#       - name: Run DVC pipeline
#         env:
#           AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
#           AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
#           DAGSHUB_PAT: ${{ secrets.DAGSHUB_PAT }}
#         run: |
#           dvc repro --quiet


#       - name: Run model loading tests
#         env:
#           DAGSHUB_PAT: ${{ secrets.DAGSHUB_PAT }}
#         run: |
#           python -m unittest discover -s tests -p "test_model.py"

#       # STEP 9: Promote latest best model to Production stage in MLflow Registry
#       - name: Promote model to production
#         if: success()
#         env:
#           DAGSHUB_PAT: ${{ secrets.DAGSHUB_PAT }}
#         run: |
#           python src/utils/utils.py

#       # STEP 10: Unit test Flask application for health and predict endpoints
#       - name: Run Flask app tests
#         if: success()
#         env:
#           DAGSHUB_PAT: ${{ secrets.DAGSHUB_PAT }}
#         run: |
#           python -m unittest tests/test_flask_app.py

#       # STEP 11: Login to AWS ECR using credentials securely stored in GitHub Secrets
#       - name: ECR Login
#         if: success()
#         run: |
#           aws configure set region $AWS_REGION
#           aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}
#           aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}
#           aws ecr get-login-password --region $AWS_REGION | docker login --username AWS --password-stdin 739275446561.dkr.ecr.$AWS_REGION.amazonaws.com

#       # STEP 12: Build Docker image
#       - name: Build docker image
#         if: success()
#         run: |
#           docker build -t prashant-mlops-ecr .

#       # STEP 13: Tag Docker image before pushing to AWS ECR
#       - name: Tag docker image
#         if: success()
#         run: |
#           docker tag prashant-mlops-ecr:latest 739275446561.dkr.ecr.$AWS_REGION.amazonaws.com/prashant-mlops-ecr:latest

#       # STEP 14: Push Docker image to AWS Elastic Container Registry (ECR)
#       - name: Docker push to ECR
#         if: success()
#         run: |
#           docker push 739275446561.dkr.ecr.$AWS_REGION.amazonaws.com/prashant-mlops-ecr:latest
      

#       # STEP 15: Deploy on EC2 (pull image in EC2 and run)
#       - name: Deploy to EC2
#         if: success()
#         uses: appleboy/ssh-action@v0.1.5 
#         with:
#           host: ${{ secrets.EC2_HOST }}
#           username: ${{ secrets.EC2_USER }}
#           key: ${{ secrets.EC2_SSH_KEY }}
#           script: |
#             aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}
#             aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}
#             aws configure set default.region $AWS_REGION
            
#             aws ecr get-login-password --region $AWS_REGION | docker login --username AWS --password-stdin 739275446561.dkr.ecr.$AWS_REGION.amazonaws.com
            
#             docker pull 739275446561.dkr.ecr.$AWS_REGION.amazonaws.com/prashant-mlops-ecr:latest
            
#             docker stop my-app || true
#             docker rm my-app || true
            
#             docker run -d -p 5000:5000 --name my-app -e DAGSHUB_PAT=${{ secrets.DAGSHUB_PAT }} 739275446561.dkr.ecr.$AWS_REGION.amazonaws.com/prashant-mlops-ecr:latest





name: CI Pipeline

on:
  push:

jobs:
  project-testing:
    runs-on: ubuntu-latest

    env:
      PYTHONPATH: ${{ github.workspace }}
      AWS_REGION: ap-south-1

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements_dev.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip --quiet
          pip install -r requirements_dev.txt --quiet

      - name: Setup DVC and Dagshub
        run: |
          pip install --quiet dvc[s3] dagshub

      - name: Pull DVC data
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          DAGSHUB_PAT: ${{ secrets.DAGSHUB_PAT }}
        run: |
          dvc pull --quiet
          test -f artifacts/data/vectorized/test_vectorized.csv

      - name: Run DVC pipeline
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          DAGSHUB_PAT: ${{ secrets.DAGSHUB_PAT }}
        run: dvc repro --quiet

      - name: Run model tests
        run: python -m unittest discover -s tests -p "test_model.py"

      - name: Promote model to production
        if: success()
        run: python src/utils/utils.py

      - name: Run Flask app tests
        if: success()
        run: python -m unittest tests/test_flask_app.py

      - name: AWS ECR Login
        run: |
          aws configure set region $AWS_REGION
          aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws ecr get-login-password --region $AWS_REGION | docker login --username AWS --password-stdin 739275446561.dkr.ecr.$AWS_REGION.amazonaws.com

      - name: Build Docker Image
        run: docker build -t prashant-mlops-ecr .

      - name: Tag Docker Image
        run: docker tag prashant-mlops-ecr:latest 739275446561.dkr.ecr.$AWS_REGION.amazonaws.com/prashant-mlops-ecr:latest

      - name: Push Docker Image
        run: docker push 739275446561.dkr.ecr.$AWS_REGION.amazonaws.com/prashant-mlops-ecr:latest

      - name: Deploy to EC2
        uses: appleboy/ssh-action@v0.1.5
        with:
          host: ${{ secrets.EC2_HOST }}
          username: ${{ secrets.EC2_USER }}
          key: ${{ secrets.EC2_SSH_KEY }}
          script: |
            set -e
            echo "Installing Docker if not installed..."
            if ! command -v docker &> /dev/null
            then
              sudo apt update
              sudo apt install docker.io -y
              sudo systemctl enable docker
              sudo systemctl start docker
            fi

            echo "Logging into AWS ECR..."
            aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}
            aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}
            aws configure set default.region $AWS_REGION
            aws ecr get-login-password --region $AWS_REGION | docker login --username AWS --password-stdin 739275446561.dkr.ecr.$AWS_REGION.amazonaws.com

            echo "Pulling latest Docker image..."
            docker pull 739275446561.dkr.ecr.$AWS_REGION.amazonaws.com/prashant-mlops-ecr:latest

            echo "Stopping and removing old container if exists..."
            docker stop my-app || true
            docker rm my-app || true

            echo "Running new Docker container..."
            docker run -d --restart always -p 5000:5000 --name my-app \
              -e DAGSHUB_PAT=${{ secrets.DAGSHUB_PAT }} \
              739275446561.dkr.ecr.$AWS_REGION.amazonaws.com/prashant-mlops-ecr:latest

            echo "Verifying container is running..."
            docker ps
